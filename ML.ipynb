{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989de9da",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "pip install h5py\n",
    "import numpy as np # linear algebra\n",
    "import h5py\n",
    "import scipy.io as io\n",
    "import sklearn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import dask.array as da\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from time import time\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, classification_report, f1_score\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d144d5",
   "metadata": {},
   "source": [
    "### Signal description\n",
    "The following modulations have been considered as classes:\n",
    "\n",
    "- 1- Linear Frequency Modulation (LFM)\n",
    "- 2- 2FSK Binary Frequency Keying\n",
    "- 3- 4FSK frequency keying\n",
    "- 4- 8FSK frequency keying\n",
    "- 5- Frequency modulation with Costas code\n",
    "- 6- 2PSK Binary Phase Shift Keying\n",
    "- 7- 4PSK Phase Keying\n",
    "- 8- 8PSK Phase Keying\n",
    "- 9- Phase modulation with Barker code\n",
    "- 10- Huffman Code Phase Modulation\n",
    "- 11- Phase modulation with Frank code\n",
    "- 12- Phase Modulation with P1 Code\n",
    "- 13- Phase Modulation with P2 Code\n",
    "- 14- Phase Modulation with P3 Code\n",
    "- 15- Phase Modulation with P4 Code\n",
    "- 16- Phase Modulation with Px Code\n",
    "- 17- Phase modulation with Zadoff-Chu code\n",
    "- 18- Phase Modulation with T1 Code\n",
    "- 19- Phase modulation with T2 code\n",
    "- 20- Phase Modulation with T3 Code\n",
    "- 21- Phase Modulation with T4 Code\n",
    "- 22- Non-Modulation (NM)\n",
    "- 23- Complex White Gaussian Noise (Noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e971015",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "your_path = 'input/'\n",
    "classes = ['LFM','2FSK','4FSK','8FSK', 'Costas','2PSK','4PSK',\\\n",
    "           '8PSK','Barker','Huffman','Frank','P1','P2','P3','P4','Px',\\\n",
    "           'Zadoff-Chu','T1','T2','T3','T4','NM','Noise']\n",
    "with h5py.File(your_path +'X_train.mat', 'r') as f:\n",
    "    X_train = np.array(f['X_train'], dtype='float32').T\n",
    "with h5py.File(your_path +'X_val.mat', 'r') as f:\n",
    "    X_val = np.array(f['X_val'], dtype='float32').T\n",
    "with h5py.File(your_path +'X_test.mat', 'r') as f:\n",
    "    X_test = np.array(f['X_test'], dtype='float32').T\n",
    "    Y_train = io.loadmat(your_path + 'Y_train.mat')['Y_train']\n",
    "Y_val = io.loadmat(your_path + 'Y_val.mat')['Y_val']\n",
    "Y_test = io.loadmat(your_path + 'Y_test.mat')['Y_test']\n",
    "lbl_train = io.loadmat(your_path + 'lbl_train.mat')['lbl_train']\n",
    "lbl_test = io.loadmat(your_path + 'lbl_test.mat')['lbl_test']\n",
    "lbl_val = io.loadmat(your_path + 'lbl_val.mat')['lbl_val']\n",
    "print(\"Sample:\")\n",
    "print(X_train.shape, X_val.shape, X_test.shape)\n",
    "print(np.isnan(X_train).sum(), np.isnan(X_val).sum(), np.isnan(X_test).sum())\n",
    "def shw_smpl(smpl, start=None, end=None):\n",
    "    label = classes[Y_train[smpl].argmax()]\n",
    "    plt.figure(figsize=(10,3))\n",
    "    plt.title(label)\n",
    "    plt.plot(X_train[smpl, start:end,0], label=\"i\")\n",
    "    plt.plot(X_train[smpl, start:end,1], label=\"q\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "for smpl in random.sample(range(X_train.shape[0]), 10):\n",
    "    shw_smpl(smpl, end=50)\n",
    "    \n",
    "pd.DataFrame(\n",
    "    data=lbl_train,\n",
    "    columns=[\n",
    "        \"Signal Class\",\n",
    "        \"Signal-to-noise ratio\",\n",
    "        \"Signal Length\",\n",
    "        \"Carrier Frequency\",\n",
    "        \"LFM Bandwidth OR Symbolic Rate\",\n",
    "        \"Frequency Jump\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "def barplot(dataframe, title=None):\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.title(title)\n",
    "    unique, counts = np.unique(dataframe.argmax(1), return_counts=True)\n",
    "    ax = sns.barplot(\n",
    "        x=np.array(classes)[unique],\n",
    "        y=counts,\n",
    "        palette=\"pastel\"\n",
    "    )\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=45, horizontalalignment='right')\n",
    "    plt.show()\n",
    "    \n",
    "barplot(Y_train, \"train\")\n",
    "barplot(Y_val, \"validation\")\n",
    "barplot(Y_test, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc0c7ed",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, filenameX, filenameY):\n",
    "        with h5py.File(your_path +filenameX + '.mat', 'r') as f:\n",
    "            x = np.array(f[filenameX], dtype='float32').T\n",
    "        y = io.loadmat(your_path + filenameY+'.mat')[filenameY]\n",
    "        self.n_samples = x.shape[0]\n",
    "        self.X = torch.from_numpy(x).view(-1, 1, 1024, 2)\n",
    "        self.y = torch.from_numpy(y).argmax(1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "    \n",
    "trainset = MyDataset(\"X_train\", \"Y_train\")\n",
    "valset = MyDataset(\"X_val\", \"Y_val\")\n",
    "testset = MyDataset(\"X_test\", \"Y_test\")\n",
    "\n",
    "# Consider increasing if high number of features.\n",
    "# Find best batch size for efficiency\n",
    "batch_size = 4096\n",
    "\n",
    "trainloader = DataLoader(trainset, shuffle=True, batch_size = batch_size)\n",
    "valloader = DataLoader(valset, shuffle=False, batch_size = batch_size)\n",
    "testloader = DataLoader(testset, shuffle=False, batch_size = batch_size)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device\n",
    "\n",
    "def test_epoch(dataloader, model):\n",
    "    model.eval()\n",
    "    true, pred = torch.empty(0).to(torch.long), torch.empty(0)\n",
    "    for batchx, batchy in tqdm(dataloader, leave=False):\n",
    "        batchx = batchx.to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model(batchx)\n",
    "            true = torch.cat((true, batchy))\n",
    "            pred = torch.cat((pred, output.cpu()))\n",
    "    return true, pred\n",
    "\n",
    "def train_epoch(dataloader, model, criterion, optimizer):\n",
    "    model.train()\n",
    "    all_, right, total_loss, count = 0, 0, 0, 0\n",
    "    for batchx, batchy in tqdm(dataloader, leave=False):\n",
    "        batchx, batchy = batchx.to(device), batchy.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(batchx)\n",
    "        loss = criterion(pred, batchy)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        all_ += batchy.shape[0]\n",
    "        right += (pred.argmax(1) == batchy).sum().cpu()\n",
    "        count += 1\n",
    "        total_loss += loss.cpu().item()\n",
    "    return (right/all_).item(), total_loss/count\n",
    "\n",
    "def get_metrics(pred, true):\n",
    "    accuracy = accuracy_score(pred, true)\n",
    "    precision = precision_score(pred, true, average=\"weighted\", zero_division=0)\n",
    "    recall = recall_score(pred, true, average=\"weighted\", zero_division=0)\n",
    "    f1 = f1_score(pred, true, average=\"weighted\", zero_division=0)\n",
    "    conf_matrix = confusion_matrix(pred, true)\n",
    "    return accuracy, precision, recall, f1, conf_matrix\n",
    "\n",
    "def init_history(*data):\n",
    "    if data:\n",
    "        data = [data]\n",
    "    return pd.DataFrame(\n",
    "        data=data,\n",
    "        columns=[\"accuracy train\",\"accuracy val\", \"train loss\",\n",
    "                 \"val loss\",\"precision\", \"recall\", \"f1\"]\n",
    "    )\n",
    "\n",
    "def model_training(model, trainloader, valloader, criterion, optimizer, epochs=20):\n",
    "    start_time = time()\n",
    "    history = init_history()\n",
    "    for epoch in range(epochs):\n",
    "        train_acc, train_loss = train_epoch(trainloader, model, criterion, optimizer)\n",
    "        true, pred = test_epoch(valloader, model)\n",
    "        val_loss = criterion(pred, true).item()\n",
    "        val_acc, val_prec, val_rec, val_f1, _ = get_metrics(pred.argmax(dim=1), true)\n",
    "        history = pd.concat((history, init_history(\n",
    "            train_acc, val_acc, train_loss,val_loss,val_prec, val_rec, val_f1\n",
    "        )),axis=0, ignore_index=True)\n",
    "        print(f\"epoch [{epoch:2d}] train loss [{train_loss:5.4f}] train acc \\\n",
    "[{train_acc:5.4f}] val loss [{val_loss:5.4f}] val acc [{val_acc:5.4f}]\")\n",
    "    total_time = (time() - start_time)/60\n",
    "    print(f\"total_time: {total_time}\")\n",
    "    return history, total_time\n",
    "\n",
    "def show_learning_curve(history, train=\"accuracy train\",val=\"accuracy val\", title=\"accuracy\"):\n",
    "    plt.figure(figsize=(8,3))\n",
    "    plt.plot(history[train], label=\"train\")\n",
    "    plt.plot(history[val], label=\"validation\")\n",
    "    plt.title(title)\n",
    "    plt.xticks(range(history.shape[0]))\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "def heatmap(congf_m):\n",
    "    plt.figure(figsize=(16,13))\n",
    "    sns.heatmap(conf_m, xticklabels=classes, yticklabels=classes, annot=True,\n",
    "                fmt=\"4d\", cmap=\"Blues\");\n",
    "    plt.show()\n",
    "\n",
    "def save_results(data=None):\n",
    "    file_exists = os.path.exists('results.csv')\n",
    "    \n",
    "    if not file_exists:\n",
    "        new_res = pd.DataFrame(\n",
    "        columns=[\"model\", \"accuracy\", \"precision\", \"recall\", \"f1\", \"time(m)\", \"params\", \"timestamp\"]\n",
    "        )\n",
    "        new_res.to_csv('results.csv')\n",
    "    \n",
    "    new_res = pd.DataFrame(data)\n",
    "    new_res.to_csv('results.csv', mode='a', header=False, index=False)\n",
    "    \n",
    "    return new_res\n",
    "\n",
    "# data=[[\"model 1\", acc, prec, rec, f1, model1_scores[1], model1_scores[0], datetime.datetime.now()]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503bf140",
   "metadata": {},
   "source": [
    "# Model 1 - Single Conv layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d69b4b0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model_name = \"single conv layer\"\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.l1 = nn.Sequential(\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.Conv2d(in_channels=1, out_channels=4, kernel_size=(3,2), padding=(1,0)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2,1)),\n",
    "            nn.Dropout2d(0.2),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(1024*2, 23),\n",
    "            nn.Softmax(dim=1),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.l1(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "model = MyModel().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.005)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6476ef1a",
   "metadata": {},
   "source": [
    "# Model 2 - Increase kernel size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28486bd9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model_name = \"single conv layer, increase kernel size\"\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.l1 = nn.Sequential(\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.Conv2d(in_channels=1, out_channels=4, kernel_size=(11,1), padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2,1)),\n",
    "            nn.Dropout2d(0.2),\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(1024*4, 23),\n",
    "            nn.Softmax(dim=1),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.l1(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "model = MyModel().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0008)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f87367",
   "metadata": {},
   "source": [
    "# Model 3 - 4 conv layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6058417a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model_name = \"8 conv small to large kernel, 4096 batch size\"\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.l1 = nn.Sequential(\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=(3,1), padding=\"same\"),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(16),\n",
    "            \n",
    "            nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(3,1), padding=\"same\"),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2,1)),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.Dropout2d(0.2),\n",
    "        )\n",
    "        self.l2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(7,1), padding=\"same\"),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            \n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(7,1), padding=\"same\"),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2,1)),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Dropout2d(0.2),\n",
    "        )\n",
    "        self.l3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(11,1), padding=\"same\"),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            \n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(11,1), padding=\"same\"),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2,1)),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Dropout2d(0.3),\n",
    "        )\n",
    "        self.l4 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(15,1), padding=\"same\"),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            \n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(15,1), padding=\"same\"),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2,1)),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Dropout2d(0.3),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128*128, 23),\n",
    "            nn.Softmax(dim=1),\n",
    "        )\n",
    "            \n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = self.l1(x)\n",
    "        x = self.l2(x)\n",
    "        x = self.l3(x)\n",
    "        x = self.l4(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "model = MyModel().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "history, total_t = model_training(model, trainloader, valloader, criterion, optimizer, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f562f04d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "history, total_t = model_training(model, trainloader, valloader, criterion, optimizer, 20)\n",
    "model_scores = [sum([p.numel() for p in model.parameters()]), total_t, history]\n",
    "with open(model_name+\".pickle\", \"wb\") as f:\n",
    "    pickle.dump(model_scores, f)\n",
    "    \n",
    "torch.save(model.state_dict(), model_name+\".pth\")\n",
    "with open(model_name+\".pickle\", \"rb\") as f:\n",
    "    model_scores = pickle.load(f)\n",
    "    \n",
    "model.load_state_dict(torch.load(model_name+\".pth\"))\n",
    "model.eval();\n",
    "\n",
    "show_learning_curve(model_scores[2], \"train loss\", \"val loss\", \"cross entropy loss\")\n",
    "show_learning_curve(model_scores[2])\n",
    "true, pred = test_epoch(testloader, model)\n",
    "acc, prec, rec, f1, conf_m = get_metrics(true, pred.argmax(dim=1))\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"Recall: {rec:.4f}\")\n",
    "print(f\"F1 score: {f1:.4f}\")\n",
    "heatmap(conf_m)\n",
    "print(classification_report(true, pred.argmax(1), zero_division=0))\n",
    "total_res = save_results(\n",
    "    data=[[model_name, acc, prec, rec, f1, model_scores[1], model_scores[0], datetime.datetime.now()]]\n",
    ")\n",
    "total_res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
